@misc{piterbarg2024editseq,
      title={Training Language Models on Synthetic Edit Sequences Improves Code Synthesis}, 
      author={Ulyana Piterbarg and Lerrel Pinto and Rob Fergus},
      year={2024},
      eprint={2410.02749},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{
    coeditor,
    title={Coeditor: Leveraging Repo-level Diffs for Code Auto-editing},
    author={Jiayi Wei and Greg Durrett and Isil Dillig},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=ALVwQjZRS8}
}

@article{overwatch,
    author = {Zhang, Yuhao and Bajpai, Yasharth and Gupta, Priyanshu and Ketkar, Ameya and Allamanis, Miltiadis and Barik, Titus and Gulwani, Sumit and Radhakrishna, Arjun and Raza, Mohammad and Soares, Gustavo and Tiwari, Ashish},
    title = {Overwatch: learning patterns in code edit sequences},
    year = {2022},
    issue_date = {October 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {6},
    number = {OOPSLA2},
    url = {https://doi.org/10.1145/3563302},
    doi = {10.1145/3563302},
    abstract = {Integrated Development Environments (IDEs) provide tool support to automate many source code editing tasks. Traditionally, IDEs use only the spatial context, i.e., the location where the developer is editing, to generate candidate edit recommendations. However, spatial context alone is often not sufficient to confidently predict the developer’s next edit, and thus IDEs generate many suggestions at a location. Therefore, IDEs generally do not actively offer suggestions and instead, the developer is usually required to click on a specific  
    icon or menu and then select from a large list of potential suggestions. As a consequence, developers often miss the opportunity to use the tool support because they are not aware it exists or forget to use it.  
    To better understand common patterns in developer behavior and produce better edit recommendations, we can additionally use the temporal context, i.e., the edits that a developer was recently performing. To enable edit recommendations based on temporal context, we present Overwatch, a novel technique for learning edit sequence patterns from traces of developers’ edits performed in an IDE. Our experiments show that Overwatch has 78\% precision and that Overwatch not only completed edits when developers missed the  
    opportunity to use the IDE tool support but also predicted new edits that have no tool support in the IDE.},
    journal = {Proc. ACM Program. Lang.},
    month = oct,
    articleno = {139},
    numpages = {29},
    keywords = {Artificial Intelligence, Program Generation, Program Synthesis}
}

@misc{cursorai,
    key ={cursorai},
    title = {
      CursorAI, the AI Code Editor.
    },
    howpublished = {\url{https://www.cursor.com/features}},
    note = {Accessed: 2024-11-06}
}

@misc{copilot, 
    key={ghcopilot},
    title={
        Github Copilot, your AI pair programmer.
    },
    howpublished = {
        \url{https://github.com/features/copilot}},
    note = {Accessed: 2024-11-06}
}

@misc{celikyilmaz2021evaluationtextgenerationsurvey,
      title={Evaluation of Text Generation: A Survey}, 
      author={Asli Celikyilmaz and Elizabeth Clark and Jianfeng Gao},
      year={2021},
      eprint={2006.14799},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.14799}, 
}

@article{jimenez2023,
  author = {Jimenez, CE and Yang, J and Wettig, A and Yao, S and Pei, K},
  title = {Swe-bench: Can Language Models Resolve Real-World GitHub Issues?},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2310.06770}
}

@article{liu2023,
  author = {Liu, T and Xu, C and McAuley, J},
  title = {Repobench: Benchmarking Repository-Level Code Auto-Completion Systems},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2306.03091}
}

@article{li2024,
  author = {Li, K and Hu, Q and Zhao, J and Chen, H and Xie, Y},
  title = {InstructCoder: Instruction Tuning Large Language Models for Code Editing},
  journal = {Proceedings of ACL},
  year = {2024},
  url = {https://aclanthology.org/2024.acl-srw.6}
}

@article{guo2024,
  author = {Guo, Q and Zeng, Z and Wang, X},
  title = {A Survey on Evaluating Large Language Models in Code Generation Tasks},
  journal = {arXiv preprint},
  year = {2024},
  url = {https://arxiv.org/abs/2408.16498}
}

@article{pandey2024,
  author = {Pandey, R and Singh, P and Wei, R and Shankar, S},
  title = {Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects},
  journal = {arXiv preprint},
  year = {2024},
  url = {https://arxiv.org/abs/2406.17910}
}

@article{pudari2023,
  author = {Pudari, R and Ernst, NA},
  title = {From Copilot to Pilot: Towards AI Supported Software Development},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2303.04142}
}

@inproceedings{coedpilot, series={ISSTA ’24},
   title={CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature},
   url={http://dx.doi.org/10.1145/3650212.3652142},
   DOI={10.1145/3650212.3652142},
   booktitle={Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
   publisher={ACM},
   author={Liu, Chenyan and Cai, Yufan and Lin, Yun and Huang, Yuhuan and Pei, Yunrui and Jiang, Bo and Yang, Ping and Dong, Jin Song and Mei, Hong},
   year={2024},
   month=sep, pages={466–478},
   collection={ISSTA ’24} 
}


@article{codeplan,
author = {Bairi, Ramakrishna and Sonwane, Atharv and Kanade, Aditya and C., Vageesh D. and Iyer, Arun and Parthasarathy, Suresh and Rajamani, Sriram and Ashok, B. and Shet, Shashank},
title = {CodePlan: Repository-Level Coding using LLMs and Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643757},
doi = {10.1145/3643757},
abstract = {Software engineering activities such as package migration, fixing error reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code.     We formulate these activities as repository-level coding tasks.         Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems.     Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt.     We frame repository-level coding as a planning problem and present a task-agnostic, neuro-symbolic framework called CodePlan to solve it.     CodePlan synthesizes a multi-step chain-of-edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions.     CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm (symbolic components) with the neural LLMs.         We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2–97 files).     Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines.     CodePlan is able to get 5/7 repositories to pass the validity checks (i.e., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them.     We provide our (non-proprietary) data, evaluation scripts and supplementary material at https://github.com/microsoft/codeplan.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {31},
numpages = {24},
keywords = {Automated coding, LLMs, chain of edits, neuro-symbolic AI, plan, repositories, static analysis}
}