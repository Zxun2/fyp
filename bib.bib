@misc{piterbarg2024editseq,
      title={Training Language Models on Synthetic Edit Sequences Improves Code Synthesis}, 
      author={Ulyana Piterbarg and Lerrel Pinto and Rob Fergus},
      year={2024},
      eprint={2410.02749},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{
    coeditor,
    title={Coeditor: Leveraging Repo-level Diffs for Code Auto-editing},
    author={Jiayi Wei and Greg Durrett and Isil Dillig},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=ALVwQjZRS8}
}

@article{overwatch,
    author = {Zhang, Yuhao and Bajpai, Yasharth and Gupta, Priyanshu and Ketkar, Ameya and Allamanis, Miltiadis and Barik, Titus and Gulwani, Sumit and Radhakrishna, Arjun and Raza, Mohammad and Soares, Gustavo and Tiwari, Ashish},
    title = {Overwatch: learning patterns in code edit sequences},
    year = {2022},
    issue_date = {October 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {6},
    number = {OOPSLA2},
    url = {https://doi.org/10.1145/3563302},
    doi = {10.1145/3563302},
    abstract = {Integrated Development Environments (IDEs) provide tool support to automate many source code editing tasks. Traditionally, IDEs use only the spatial context, i.e., the location where the developer is editing, to generate candidate edit recommendations. However, spatial context alone is often not sufficient to confidently predict the developer’s next edit, and thus IDEs generate many suggestions at a location. Therefore, IDEs generally do not actively offer suggestions and instead, the developer is usually required to click on a specific  
    icon or menu and then select from a large list of potential suggestions. As a consequence, developers often miss the opportunity to use the tool support because they are not aware it exists or forget to use it.  
    To better understand common patterns in developer behavior and produce better edit recommendations, we can additionally use the temporal context, i.e., the edits that a developer was recently performing. To enable edit recommendations based on temporal context, we present Overwatch, a novel technique for learning edit sequence patterns from traces of developers’ edits performed in an IDE. Our experiments show that Overwatch has 78\% precision and that Overwatch not only completed edits when developers missed the  
    opportunity to use the IDE tool support but also predicted new edits that have no tool support in the IDE.},
    journal = {Proc. ACM Program. Lang.},
    month = oct,
    articleno = {139},
    numpages = {29},
    keywords = {Artificial Intelligence, Program Generation, Program Synthesis}
}

@misc{cursorai,
    key ={cursorai},
    title = {
      CursorAI, the AI Code Editor.
    },
    howpublished = {\url{https://www.cursor.com/features}},
    note = {Accessed: 2024-11-06}
}

@misc{copilot, 
    key={ghcopilot},
    title={
        Github Copilot, your AI pair programmer.
    },
    howpublished = {
        \url{https://github.com/features/copilot}},
    note = {Accessed: 2024-11-06}
}

@misc{codeium,
    key={codeium},
    title={
        Codeium, your modern coding superpowers. 
    },
    howpublished = {
        \url{https://codeium.com/}
    },
    note={Accessed: 2025-01-30}
}

@misc{marscode,
    key = {marscode},
    title={
        MarsCode - AI IDE.
    },
    howpublished = {
         \url{https://marscode.com/}
    },
    note={Accessed: 2025-01-30}
}

@misc{celikyilmaz2021evaluationtextgenerationsurvey,
      title={Evaluation of Text Generation: A Survey}, 
      author={Asli Celikyilmaz and Elizabeth Clark and Jianfeng Gao},
      year={2021},
      eprint={2006.14799},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.14799}, 
}

@article{jimenez2023,
  author = {Jimenez, CE and Yang, J and Wettig, A and Yao, S and Pei, K},
  title = {Swe-bench: Can Language Models Resolve Real-World GitHub Issues?},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2310.06770}
}

@article{liu2023,
  author = {Liu, T and Xu, C and McAuley, J},
  title = {Repobench: Benchmarking Repository-Level Code Auto-Completion Systems},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2306.03091}
}

@article{li2024,
  author = {Li, K and Hu, Q and Zhao, J and Chen, H and Xie, Y},
  title = {InstructCoder: Instruction Tuning Large Language Models for Code Editing},
  journal = {Proceedings of ACL},
  year = {2024},
  url = {https://aclanthology.org/2024.acl-srw.6}
}

@article{guo2024,
  author = {Guo, Q and Zeng, Z and Wang, X},
  title = {A Survey on Evaluating Large Language Models in Code Generation Tasks},
  journal = {arXiv preprint},
  year = {2024},
  url = {https://arxiv.org/abs/2408.16498}
}

@article{pandey2024,
  author = {Pandey, R and Singh, P and Wei, R and Shankar, S},
  title = {Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects},
  journal = {arXiv preprint},
  year = {2024},
  url = {https://arxiv.org/abs/2406.17910}
}

@article{pudari2023,
  author = {Pudari, R and Ernst, NA},
  title = {From Copilot to Pilot: Towards AI Supported Software Development},
  journal = {arXiv preprint},
  year = {2023},
  url = {https://arxiv.org/abs/2303.04142}
}

@inproceedings{coedpilot, series={ISSTA ’24},
   title={CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature},
   url={http://dx.doi.org/10.1145/3650212.3652142},
   DOI={10.1145/3650212.3652142},
   booktitle={Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
   publisher={ACM},
   author={Liu, Chenyan and Cai, Yufan and Lin, Yun and Huang, Yuhuan and Pei, Yunrui and Jiang, Bo and Yang, Ping and Dong, Jin Song and Mei, Hong},
   year={2024},
   month=sep, pages={466–478},
   collection={ISSTA ’24} 
}


@article{codeplan,
author = {Bairi, Ramakrishna and Sonwane, Atharv and Kanade, Aditya and C., Vageesh D. and Iyer, Arun and Parthasarathy, Suresh and Rajamani, Sriram and Ashok, B. and Shet, Shashank},
title = {CodePlan: Repository-Level Coding using LLMs and Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643757},
doi = {10.1145/3643757},
abstract = {Software engineering activities such as package migration, fixing error reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code.     We formulate these activities as repository-level coding tasks.         Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems.     Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt.     We frame repository-level coding as a planning problem and present a task-agnostic, neuro-symbolic framework called CodePlan to solve it.     CodePlan synthesizes a multi-step chain-of-edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions.     CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm (symbolic components) with the neural LLMs.         We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2–97 files).     Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines.     CodePlan is able to get 5/7 repositories to pass the validity checks (i.e., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them.     We provide our (non-proprietary) data, evaluation scripts and supplementary material at https://github.com/microsoft/codeplan.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {31},
numpages = {24},
keywords = {Automated coding, LLMs, chain of edits, neuro-symbolic AI, plan, repositories, static analysis}
}

@article{guan2024contextmodule,
  title={ContextModule: Improving Code Completion via Repository-level Contextual Information},
  author={Guan, Zhanming and Liu, Junlin and Liu, Jierui and Peng, Chao and Liu, Dexin and Sun, Ningyuan and Jiang, Bo and Li, Wenchao and Liu, Jie and Zhu, Hang},
  journal={arXiv preprint arXiv:2412.08063},
  year={2024}
}

@misc{banerjee2024contextmatterspushingboundaries,
      title={Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context}, 
      author={Somnath Banerjee and Amruit Sahoo and Sayan Layek and Avik Dutta and Rima Hazra and Animesh Mukherjee},
      year={2024},
      eprint={2401.12671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.12671}, 
}

@misc{guo2024largelanguagemodelbased,
      title={Large Language Model based Multi-Agents: A Survey of Progress and Challenges}, 
      author={Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
      year={2024},
      eprint={2402.01680},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01680}, 
}

@misc{park2023generativeagentsinteractivesimulacra,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2304.03442}, 
}

@misc{li2023camelcommunicativeagentsmind,
      title={CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society}, 
      author={Guohao Li and Hasan Abed Al Kader Hammoud and Hani Itani and Dmitrii Khizbullin and Bernard Ghanem},
      year={2023},
      eprint={2303.17760},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.17760}, 
}

@misc{light2023avalonbenchevaluatingllmsplaying,
      title={AvalonBench: Evaluating LLMs Playing the Game of Avalon}, 
      author={Jonathan Light and Min Cai and Sheng Shen and Ziniu Hu},
      year={2023},
      eprint={2310.05036},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.05036}, 
}

@misc{hua2024warpeacewaragentlarge,
      title={War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars}, 
      author={Wenyue Hua and Lizhou Fan and Lingyao Li and Kai Mei and Jianchao Ji and Yingqiang Ge and Libby Hemphill and Yongfeng Zhang},
      year={2024},
      eprint={2311.17227},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.17227}, 
}

@misc{li2024econagentlargelanguagemodelempowered,
      title={EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities}, 
      author={Nian Li and Chen Gao and Mingyu Li and Yong Li and Qingmin Liao},
      year={2024},
      eprint={2310.10436},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.10436}, 
}

@misc{zhang2024generativeagentsrecommendation,
      title={On Generative Agents in Recommendation}, 
      author={An Zhang and Yuxin Chen and Leheng Sheng and Xiang Wang and Tat-Seng Chua},
      year={2024},
      eprint={2310.10108},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.10108}, 
}

@article{Ghaffarzadegan_2024,
   title={Generative agent‐based modeling: an introduction and tutorial},
   volume={40},
   ISSN={1099-1727},
   url={http://dx.doi.org/10.1002/sdr.1761},
   DOI={10.1002/sdr.1761},
   number={1},
   journal={System Dynamics Review},
   publisher={Wiley},
   author={Ghaffarzadegan, Navid and Majumdar, Aritra and Williams, Ross and Hosseinichimeh, Niyousha},
   year={2024},
   month=jan }


@misc{du2023improving,
    title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
    author={Yilun Du and Shuang Li and Antonio Torralba and Joshua B. Tenenbaum and Igor Mordatch},
    year={2023},
    eprint={2305.14325},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{Xiong_2023,
   title={Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate},
   url={http://dx.doi.org/10.18653/v1/2023.findings-emnlp.508},
   DOI={10.18653/v1/2023.findings-emnlp.508},
   booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
   publisher={Association for Computational Linguistics},
   author={Xiong, Kai and Ding, Xiao and Cao, Yixin and Liu, Ting and Qin, Bing},
   year={2023},
   pages={7572–7590} }


@misc{tang2024medagentslargelanguagemodels,
      title={MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning}, 
      author={Xiangru Tang and Anni Zou and Zhuosheng Zhang and Ziming Li and Yilun Zhao and Xingyao Zhang and Arman Cohan and Mark Gerstein},
      year={2024},
      eprint={2311.10537},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.10537}, 
}

@misc{ye2024isolationmultiagentsynergyimproving,
      title={Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction}, 
      author={Hongbin Ye and Honghao Gui and Aijia Zhang and Tong Liu and Weiqiang Jia},
      year={2024},
      eprint={2312.03022},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2312.03022}, 
}

@misc{xu2024retrievalmeetslongcontext,
      title={Retrieval meets Long Context Large Language Models}, 
      author={Peng Xu and Wei Ping and Xianchao Wu and Lawrence McAfee and Chen Zhu and Zihan Liu and Sandeep Subramanian and Evelina Bakhturina and Mohammad Shoeybi and Bryan Catanzaro},
      year={2024},
      eprint={2310.03025},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03025}, 
}

@misc{yan2024correctiveretrievalaugmentedgeneration,
      title={Corrective Retrieval Augmented Generation}, 
      author={Shi-Qi Yan and Jia-Chen Gu and Yun Zhu and Zhen-Hua Ling},
      year={2024},
      eprint={2401.15884},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.15884}, 
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{claude,
    key = {claude},
    title={
        Claude 3 Model Card.
    } ,
    howpublished={
        \url{https://assets.anthropic.com/m/61e7d27f8c8f5919/original/Claude-3-Model-Card.pdf}
    },
    note={Accessed=2025-01-30}
}

@misc{liu2023lostmiddlelanguagemodels,
      title={Lost in the Middle: How Language Models Use Long Contexts}, 
      author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
      year={2023},
      eprint={2307.03172},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03172}, 
}

@misc{perez2020unsupervisedquestiondecompositionquestion,
      title={Unsupervised Question Decomposition for Question Answering}, 
      author={Ethan Perez and Patrick Lewis and Wen-tau Yih and Kyunghyun Cho and Douwe Kiela},
      year={2020},
      eprint={2002.09758},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2002.09758}, 
}

@misc{khot2023decomposedpromptingmodularapproach,
      title={Decomposed Prompting: A Modular Approach for Solving Complex Tasks}, 
      author={Tushar Khot and Harsh Trivedi and Matthew Finlayson and Yao Fu and Kyle Richardson and Peter Clark and Ashish Sabharwal},
      year={2023},
      eprint={2210.02406},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.02406}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{zhou2023leasttomostpromptingenablescomplex,
      title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models}, 
      author={Denny Zhou and Nathanael Schärli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc Le and Ed Chi},
      year={2023},
      eprint={2205.10625},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2205.10625}, 
}

@misc{sun2023pearlpromptinglargelanguage,
      title={PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents}, 
      author={Simeng Sun and Yang Liu and Shuohang Wang and Chenguang Zhu and Mohit Iyyer},
      year={2023},
      eprint={2305.14564},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14564}, 
}

@article{copilotx,
    author = "Github",
    title = "Inside GitHub: Working with the LLMs behind GitHub Copilot",
    journal = "Github Blog",
    year =  "2024",
    note = "Accessed: 2025-01-29"
}

@misc{bavarian2022efficienttraininglanguagemodels,
      title={Efficient Training of Language Models to Fill in the Middle}, 
      author={Mohammad Bavarian and Heewoo Jun and Nikolas Tezak and John Schulman and Christine McLeavey and Jerry Tworek and Mark Chen},
      year={2022},
      eprint={2207.14255},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2207.14255}, 
}

@misc{cirisci2022pragmaticapproachstatefulpartial,
      title={A Pragmatic Approach to Stateful Partial Order Reduction}, 
      author={Berk Cirisci and Constantin Enea and Azadeh Farzan and Suha Orhun Mutluergil},
      year={2022},
      eprint={2211.11942},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2211.11942}, 
}